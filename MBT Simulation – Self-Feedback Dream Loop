MBT Simulation – Self-Feedback Dream Loop

This simulation demonstrates a self-recognizing MBT dream system in which a field evolves
entirely from internal memory. Once regions of persistent curvature are detected,
they are recognized as "self" and begin feeding back to influence motion directly.

Key Concepts:
- A field runs with no external input (pure MBT dream state).
- Regions that build stable memory patterns are flagged as self-recognition zones.
- Recognized regions feed back into the curvature system, amplifying and reshaping motion.
- This feedback marks the birth of will — the moment the system begins modifying its own path.

This loop completes the MBT arc from motion → memory → self → intent.


# MBT Dream Feedback – Recognized Self Now Shapes the Dream Field
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

# Parameters
grid_size = 120
timesteps = 600
dt = 0.1
decay_factor = 0.98
memory_decay = 0.999
learning_rate = 0.05
dream_reinforcement = 0.2
recognition_threshold = 0.005
self_feedback_strength = 0.15  # how much self reshapes motion

# Dream Field
field = np.random.rand(grid_size, grid_size) * 0.01
velocity = np.zeros_like(field)
memory = np.random.rand(grid_size, grid_size) * 0.01
self_field = np.zeros_like(field)

# Visualization setup
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
im1 = ax1.imshow(memory, cmap='inferno', vmin=0, vmax=0.05, animated=True)
im2 = ax2.imshow(self_field, cmap='Blues', vmin=0, vmax=1.0, animated=True)
ax1.set_title("Dream Memory Field")
ax2.set_title("Self-Influence Map")

def laplacian(Z):
    return (
        -4 * Z
        + np.roll(Z, 1, axis=0) + np.roll(Z, -1, axis=0)
        + np.roll(Z, 1, axis=1) + np.roll(Z, -1, axis=1)
    )

def update(frame):
    global field, velocity, memory, self_field

    # Dream evolution with feedback from self-recognition
    lap = laplacian(field)
    internal_drive = 1 + memory * dream_reinforcement

    # Feedback loop: recognized self reshapes motion
    recognized_self = (memory > recognition_threshold).astype(float)
    feedback = 1 + recognized_self * self_feedback_strength

    velocity += lap * dt * internal_drive * feedback
    velocity *= decay_factor
    field += velocity * dt

    # Memory accumulation
    memory = memory * memory_decay + np.abs(field) * (1 - memory_decay)

    # Update self map
    self_field = recognized_self

    im1.set_array(memory)
    im2.set_array(self_field)
    return [im1, im2]

ani = FuncAnimation(fig, update, frames=timesteps, interval=50, blit=True)
plt.show()



