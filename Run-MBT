# run_mbt.py â€” MBT benchmark runner

import json
from mbt_core import classify

def load_benchmark(path):
    with open(path, "r", encoding="utf-8") as f:
        return [json.loads(line.strip()) for line in f if line.strip()]

def run_mbt(input_path, output_path):
    data = load_benchmark(input_path)
    results = []

    for item in data:
        premise = item.get("premise", {})
        query = item.get("query", {})
        result = classify(premise, query)
        results.append({
            "id": item.get("id"),
            "domain": item.get("domain"),
            "type": result["type"],
            "note": result["note"],
            "repair": result["repair"]
        })

    with open(output_path, "w", encoding="utf-8") as f:
        for r in results:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")

    print(f"âœ… MBT audit complete. {len(results)} items processed.")
    print(f"ðŸ“„ Results saved to: {output_path}")

if __name__ == "__main__":
    # Example usage
    run_mbt("benchmarks/mbt_test_input.jsonl", "outputs/audit_results.jsonl")
